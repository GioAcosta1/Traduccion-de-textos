{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GioAcosta1/Traduccion-de-textos/blob/main/Mecanismos_de_atencion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg90deR13qYE"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/041_attention/attention.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kzp2jHl3qY7"
      },
      "source": [
        "# Mecanismos de Atenci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRBwRd5q-Tc_"
      },
      "source": [
        "En el [post](https://sensioai.com/blog/040_encoder_decoder) anterior aprendimos a implementar una arquitectura de red neuronal conocida como `seq2seq`, que utiliza dos redes neuronales (el `encoder` y el `decoder`) para poder trabajar con secuencias de longitud arbitraria tanto a sus entradas como en las salidas. Este modelo nos permite llevar a cabo tareas tales como la traducci√≥n de texto entre dos idiomas, resumir un texto, responder preguntas, etc.\n",
        "\n",
        "![](https://pytorch.org/tutorials/_images/seq2seq.png)\n",
        "\n",
        "Si bien este modelo nos dio buenos resultados, podemos mejorarlo. Si prestamos atenci√≥n a la arquitectura que desarrollamos, el `decoder` (encargado de generar la secuencia de salida) es inicializado con el √∫ltimo estado oculto del `encoder`, el cual tiene la responsabilidad de codificar el significado de toda la frase original. Esto puede ser complicado, sobre todo al trabajar con secuencias muy largas, y para solventar este problema podemos utilizar un mecanismo de `atenci√≥n` que no solo reciba el √∫ltimo estado oculto si no tambi√©n tenga acceso a todas las salidas del `encoder` de manera que el `decoder` sea capaz de \"focalizar su atenci√≥n\" en aquellas partes m√°s importantes. Por ejemplo, para traducir la primera palabra es l√≥gico pensar que lo m√°s importante ser√° la primera palabra y sus adyacentes en la frase original, pero usar el √∫ltimo estado oculto del `encoder` puede no ser suficiente para mantener estas relaciones a largo plazo. Permitir al `decoder` acceder a esta informaci√≥n puede resultar en mejores prestaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybzVPx8P-TdA"
      },
      "source": [
        "> üí° En la pr√°ctica, los mecanismos de atenci√≥n dan muy buenos resultados en tareas que envuelvan datos secuenciales (como aplicaciones de lenguaje). De hecho, los mejores modelos a d√≠a de hoy para tareas de `NLP` no est√°n basados en redes recurrentes sino en arquitecturas que √∫nicamente implementan mecanismos de atenci√≥n en varias capas. Estas redes neuronales son conocidas como `Transformers`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3O225-E-TdD"
      },
      "source": [
        "## El *dataset*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-03T08:31:48.390280Z",
          "start_time": "2020-09-03T08:31:48.382280Z"
        },
        "id": "iuq7BL11-TdD"
      },
      "source": [
        "Vamos a resolver exactamente el mismo caso que en el post anterior, as√≠ que todo lo que hace referencia al procesado de datos lo dejaremos igual."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txXlqPPS-kTi",
        "outputId": "533f356e-293e-4f27-c259-77e4d9075320"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:52.733066Z",
          "start_time": "2020-09-04T12:31:52.725066Z"
        },
        "id": "Yb9LC0Jw-TdE"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "def read_file(file, reverse=False):\n",
        "    # Read the file and split into lines\n",
        "    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n",
        "\n",
        "    return pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.056055Z",
          "start_time": "2020-09-04T12:31:52.735065Z"
        },
        "id": "Te1Sc3Nr-TdG"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/drive/MyDrive/DEEP LEARNING/TRANSLATION PROYECT/deu.txt'\n",
        "pairs = read_file(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.071561Z",
          "start_time": "2020-09-04T12:31:56.058156Z"
        },
        "id": "Ds822BD0-TdH",
        "outputId": "be779abc-0d75-4e0b-990c-c2e0c55f02a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tom must choose between honor and death .',\n",
              " 'tom muss die ehre wahlen oder aber den tod .']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "random.choice(pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.087569Z",
          "start_time": "2020-09-04T12:31:56.074570Z"
        },
        "id": "qXe75QP5-TdI"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "PAD_token = 2\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\"SOS\": 0, \"EOS\": 1, \"PAD\": 2}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\"}\n",
        "        self.n_words = 3  # Count SOS, EOS and PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "            \n",
        "    def indexesFromSentence(self, sentence):\n",
        "        return [self.word2index[word] for word in sentence.split(' ')]\n",
        "    \n",
        "    def sentenceFromIndex(self, index):\n",
        "        return [self.index2word[ix] for ix in index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDKoy-zA-TdJ"
      },
      "source": [
        "Para poder aplicar la capa de `attention` necesitamos que nuestras frases tengan una longitud m√°xima definida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.103564Z",
          "start_time": "2020-09-04T12:31:56.088570Z"
        },
        "id": "LmnmiXwS-TdJ"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPairs(pairs, filters, lang=0):\n",
        "    return [p for p in pairs if p[lang].startswith(filters)]\n",
        "\n",
        "def trimPairs(pairs):\n",
        "    return [p for p in pairs if len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.717657Z",
          "start_time": "2020-09-04T12:31:56.104565Z"
        },
        "code_folding": [
          0
        ],
        "id": "RTNhpWth-TdJ",
        "outputId": "000e8e8a-b63e-4f6e-ea5a-fafa6499bf24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tenemos 255817 pares de frases\n",
            "Tenemos 196685 pares de frases con longitud menor de 10\n",
            "Longitud vocabularios:\n",
            "spa 13904\n",
            "eng 28105\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i m unhappy . EOS', 'ich bin unglucklich . EOS']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def prepareData(file, filters=None, reverse=False):\n",
        "    \n",
        "    pairs = read_file(file, reverse)\n",
        "    print(f\"Tenemos {len(pairs)} pares de frases\")\n",
        "    \n",
        "    if filters is not None:\n",
        "        pairs = filterPairs(pairs, filters, int(reverse))\n",
        "        print(f\"Filtramos a {len(pairs)} pares de frases\")\n",
        "        \n",
        "    pairs = trimPairs(pairs)\n",
        "    print(f\"Tenemos {len(pairs)} pares de frases con longitud menor de {MAX_LENGTH}\")\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang('eng')\n",
        "        output_lang = Lang('spa')\n",
        "    else:\n",
        "        input_lang = Lang('spa')\n",
        "        output_lang = Lang('eng')\n",
        "    \n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "        \n",
        "        # add <eos> token\n",
        "        pair[0] += \" EOS\"\n",
        "        pair[1] += \" EOS\"\n",
        "                           \n",
        "    print(\"Longitud vocabularios:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "                           \n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData(filepath)\n",
        "\n",
        "# descomentar para usar el dataset filtrado\n",
        "#input_lang, output_lang, pairs = prepareData('spa.txt', filters=eng_prefixes)\n",
        "                           \n",
        "random.choice(pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.730653Z",
          "start_time": "2020-09-04T12:31:59.719659Z"
        },
        "scrolled": true,
        "id": "ob2pRSmq-TdK",
        "outputId": "9a312934-6211-4be4-9aea-eb06f8804a94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[477, 90, 400]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "input_lang.indexesFromSentence('forgive us ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.754653Z",
          "start_time": "2020-09-04T12:31:59.731654Z"
        },
        "id": "-ti3rQ-B-TdK",
        "outputId": "6c69a525-cf9f-4ca5-bb44-02e830bcb477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['geh', 'deins', 'nuchtern', 'hallo']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "output_lang.sentenceFromIndex([3, 1028, 647, 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBiO83gw-TdL"
      },
      "source": [
        "En el `Dataset` nos aseguraremos de a√±adir el *padding* necesario para que todas las frases tengan la misma longitud, lo cual no hace necesario utilizar la funci√≥n `collate` que implementamos en el post anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:00.233655Z",
          "start_time": "2020-09-04T12:31:59.756655Z"
        },
        "code_folding": [],
        "id": "pKDqBMvQ-TdL",
        "outputId": "ad4d9203-8751-437d-84ef-e6618003b780",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(157348, 39337)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, input_lang, output_lang, pairs, max_length):\n",
        "        self.input_lang = input_lang\n",
        "        self.output_lang = output_lang\n",
        "        self.pairs = pairs\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "        \n",
        "    def __getitem__(self, ix):        \n",
        "        inputs = torch.tensor(self.input_lang.indexesFromSentence(self.pairs[ix][0]), device=device, dtype=torch.long)\n",
        "        outputs = torch.tensor(self.output_lang.indexesFromSentence(self.pairs[ix][1]), device=device, dtype=torch.long)\n",
        "        # metemos padding a todas las frases hast a la longitud m√°xima\n",
        "        return torch.nn.functional.pad(inputs, (0, self.max_length - len(inputs)), 'constant', self.input_lang.word2index['PAD']), \\\n",
        "            torch.nn.functional.pad(outputs, (0, self.max_length - len(outputs)), 'constant', self.output_lang.word2index['PAD'])\n",
        "\n",
        "# separamos datos en train-test\n",
        "train_size = len(pairs) * 80 // 100 \n",
        "train = pairs[:train_size]\n",
        "test = pairs[train_size:]\n",
        "\n",
        "dataset = {\n",
        "    'train': Dataset(input_lang, output_lang, train, max_length=MAX_LENGTH),\n",
        "    'test': Dataset(input_lang, output_lang, test, max_length=MAX_LENGTH)\n",
        "}\n",
        "\n",
        "len(dataset['train']), len(dataset['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.359235Z",
          "start_time": "2020-09-04T12:32:00.234660Z"
        },
        "id": "eNwolvil-TdL",
        "outputId": "9e64b6d2-3fe0-4bf2-8f57-dbbcca330157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5, 4, 1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
              " tensor([5, 6, 1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "input_sentence, output_sentence = dataset['train'][1]\n",
        "\n",
        "input_sentence, output_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.374232Z",
          "start_time": "2020-09-04T12:32:01.360239Z"
        },
        "id": "9U4jvnN3-TdM",
        "outputId": "c14e6755-1f54-4e08-cdfc-89dfb21cafce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['hi', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'],\n",
              " ['hallo', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.405231Z",
          "start_time": "2020-09-04T12:32:01.375236Z"
        },
        "id": "z5eB75Dh-TdM",
        "outputId": "7bb0183a-927d-4159-dc82-2cbf2be3e668",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 10]), torch.Size([64, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=64, shuffle=True),\n",
        "    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=256, shuffle=False),\n",
        "}\n",
        "\n",
        "inputs, outputs = next(iter(dataloader['train']))\n",
        "inputs.shape, outputs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T08:13:53.670033Z",
          "start_time": "2020-09-04T08:13:53.652976Z"
        },
        "id": "7fyrrO85-TdM"
      },
      "source": [
        "## El modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0UYeHEG-TdN"
      },
      "source": [
        "En lo que se refiere al `encoder`, seguimos usando exactamente la misma arquitectura. La √∫nica diferencia es que, adem√°s del √∫ltimo estado oculto, necesitaremos todas sus salidas para que el `decoder` pueda usarlas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.421231Z",
          "start_time": "2020-09-04T12:32:01.406231Z"
        },
        "id": "PepdDJ_S-TdN"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
        "        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, input_sentences):\n",
        "        embedded = self.embedding(input_sentences)\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.452231Z",
          "start_time": "2020-09-04T12:32:01.422235Z"
        },
        "id": "nqc_34ET-TdN",
        "outputId": "ccad04b0-db2b-4bee-f8b2-a0aff4202c17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "encoder = Encoder(input_size=input_lang.n_words)\n",
        "encoder_outputs, encoder_hidden = encoder(torch.randint(0, input_lang.n_words, (64, 10)))\n",
        "\n",
        "# [batch size, seq len, hidden size]\n",
        "encoder_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.468231Z",
          "start_time": "2020-09-04T12:32:01.453237Z"
        },
        "id": "oO2I-3pO-TdO",
        "outputId": "5b5edd34-9c14-4dac-a498-65d7c1a567ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# [num layers, batch size, hidden size]\n",
        "encoder_hidden.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdGp8SJs-TdO"
      },
      "source": [
        "### El *decoder* con *attention*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9zafPl6-TdO"
      },
      "source": [
        "Vamos a ver un ejemplo de implementaci√≥n de una capa de atenci√≥n para nuestro `decoder`. En primer lugar tendremos una capa lineal que recibir√° como entradas los `embeddings` y el estado oculto anterior (concatenados). Esta capa lineal nos dar√° a la salida tantos valores como elementos tengamos en nuestras secuencias de entrada (recuerda que las hemos forzado a tener una longitud determinada). Despu√©s, aplicaremos una funci√≥n `softmax` sobre estos valores obteniendo as√≠ una distribuci√≥n de probabilidad que, seguidamente, multiplicaremos por los *outputs* del encoder (que tambi√©n tienen la misma longitud). En esta funci√≥n de probabilidad, cada elemento tiene un valor entre 0 y 1. As√≠ pues, esta operaci√≥n dar√° m√°s importancia a aquellos *outputs* del `encoder` m√°s importantes mientras que al resto les asignar√° unos valores cercanos a 0. A continuaci√≥n, concatenaremos estos valores con los `embeddings`, de nuevo, y se lo daremos a una nueva capa lineal que combinar√° estos `embeddings` con los *outputs* del `encoder` re-escalados para obtener as√≠ los *inputs* finales de la capa recurrente. \n",
        "\n",
        "En resumen, usaremos las entradas y estado oculto del `decoder` para encontrar unos pesos que re-escalar√°n las salidas del `encoder`, los cuales combinaremos de nuevo con las entradas del `decoder` para obtener las representaciones finales de nuestras frases que alimentan la capa recurrente.\n",
        "\n",
        "![](https://i.imgur.com/1152PYf.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:43:51.447608Z",
          "start_time": "2020-09-04T13:43:51.433585Z"
        },
        "id": "EHLuOlsj-TdP"
      },
      "outputs": [],
      "source": [
        "class AttnDecoder(torch.nn.Module):\n",
        "    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2, max_length=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
        "        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
        "        self.out = torch.nn.Linear(hidden_size, input_size)\n",
        "        \n",
        "        # attention\n",
        "        self.attn = torch.nn.Linear(hidden_size + embedding_size, max_length)\n",
        "        self.attn_combine = torch.nn.Linear(hidden_size * 2, hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, input_words, hidden, encoder_outputs):\n",
        "        # sacamos los embeddings\n",
        "        embedded = self.embedding(input_words)\n",
        "        # calculamos los pesos de la capa de atenci√≥n\n",
        "        attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1))) \n",
        "        # re-escalamos los outputs del encoder con estos pesos\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
        "        output = torch.cat((embedded.squeeze(1), attn_applied.squeeze(1)), 1)\n",
        "        # aplicamos la capa de atenci√≥n\n",
        "        output = self.attn_combine(output)\n",
        "        output = torch.nn.functional.relu(output)\n",
        "        # a partir de aqu√≠, como siempre. La diferencia es que la entrada a la RNN\n",
        "        # no es directmanete el embedding sino una combinaci√≥n del embedding\n",
        "        # y las salidas del encoder re-escaladas\n",
        "        output, hidden = self.gru(output.unsqueeze(1), hidden)\n",
        "        output = self.out(output.squeeze(1))        \n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.539231Z",
          "start_time": "2020-09-04T12:32:01.484236Z"
        },
        "id": "PT4kLJ7M-TdP",
        "outputId": "5d14af6d-0bee-439c-e5ce-747810a512d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-bc211ece5c6b>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 28105])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "decoder = AttnDecoder(input_size=output_lang.n_words)\n",
        "decoder_output, decoder_hidden, attn_weights = decoder(torch.randint(0, output_lang.n_words, (64, 1)), encoder_hidden, encoder_outputs)\n",
        "\n",
        "# [batch size, vocab size]\n",
        "decoder_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.547232Z",
          "start_time": "2020-09-04T12:32:01.541233Z"
        },
        "id": "A55cOQRH-TdQ",
        "outputId": "7236fb94-acca-453e-bd7b-20b6ff4ea6e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# [num layers, batch size, hidden size]\n",
        "decoder_hidden.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.572231Z",
          "start_time": "2020-09-04T12:32:01.548231Z"
        },
        "id": "UPC0BQna-TdQ",
        "outputId": "56650d69-b38c-4288-aaac-d4fa51075134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# [num layers, batch size, hidden size]\n",
        "decoder_hidden.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.578233Z",
          "start_time": "2020-09-04T12:32:01.573232Z"
        },
        "id": "ep23mzzU-TdQ",
        "outputId": "06fd974f-f856-4bc3-bdab-c5160088752c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# [batch size, max_length]\n",
        "attn_weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or4e2C0m-TdQ"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAjH0Drz-TdR"
      },
      "source": [
        "Vamos a implementar el bucle de entrenamiento. En primer lugar, al tener ahora dos redes neuronales, necesitaremos dos optimizadores (uno para el `encoder` y otro para el `decoder`). Al `encoder` le pasaremos la frase en el idioma original, y obtendremos el estado oculto final. Este estado oculto lo usaremos para inicializar el `decoder` que, junto al token `<sos>`, generar√° la primera palabra de la frase traducida. Repetiremos el proceso, utilizando como entrada la anterior salida del decoder, hasta obtener el token `<eos>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.593231Z",
          "start_time": "2020-09-04T12:32:01.579232Z"
        },
        "code_folding": [
          3
        ],
        "id": "9_o25Nh4-TdR"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def fit(encoder, decoder, dataloader, epochs=10):\n",
        "    encoder.to(device)\n",
        "    decoder.to(device)\n",
        "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        train_loss = []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            input_sentences, output_sentences = batch\n",
        "            bs = input_sentences.shape[0]                    \n",
        "            loss = 0\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "            # obtenemos el √∫ltimo estado oculto del encoder\n",
        "            encoder_outputs, hidden = encoder(input_sentences)\n",
        "            # calculamos las salidas del decoder de manera recurrente\n",
        "            decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
        "            for i in range(output_sentences.shape[1]):\n",
        "                output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "                loss += criterion(output, output_sentences[:, i].view(bs))     \n",
        "                # el siguiente input ser√° la palabra predicha\n",
        "                decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
        "            # optimizaci√≥n\n",
        "            loss.backward()\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            bar.set_description(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f}\")\n",
        "            \n",
        "        val_loss = []\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        with torch.no_grad():\n",
        "            bar = tqdm(dataloader['test'])\n",
        "            for batch in bar:\n",
        "                input_sentences, output_sentences = batch\n",
        "                bs = input_sentences.shape[0]  \n",
        "                loss = 0\n",
        "                # obtenemos el √∫ltimo estado oculto del encoder\n",
        "                encoder_outputs, hidden = encoder(input_sentences)\n",
        "                # calculamos las salidas del decoder de manera recurrente\n",
        "                decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
        "                for i in range(output_sentences.shape[1]):\n",
        "                    output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "                    loss += criterion(output, output_sentences[:, i].view(bs))     \n",
        "                    # el siguiente input ser√° la palabra predicha\n",
        "                    decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
        "                val_loss.append(loss.item())\n",
        "                bar.set_description(f\"Epoch {epoch}/{epochs} val_loss {np.mean(val_loss):.5f}\")\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:58:02.367102Z",
          "start_time": "2020-09-04T12:32:01.595236Z"
        },
        "id": "QF04SFW7-TdR",
        "outputId": "8d4d62ea-25fb-49d3-86ca-94ce37b90cc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2459 [00:00<?, ?it/s]<ipython-input-29-bc211ece5c6b>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n",
            "Epoch 1/30 loss 31.28985: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:22<00:00, 29.94it/s]\n",
            "Epoch 1/30 val_loss 41.73479: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 20.37it/s]\n",
            "Epoch 2/30 loss 23.42449: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:19<00:00, 30.98it/s]\n",
            "Epoch 2/30 val_loss 38.71156: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.28it/s]\n",
            "Epoch 3/30 loss 20.23360: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:18<00:00, 31.20it/s]\n",
            "Epoch 3/30 val_loss 37.29097: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.68it/s]\n",
            "Epoch 4/30 loss 18.08396: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:18<00:00, 31.41it/s]\n",
            "Epoch 4/30 val_loss 36.13682: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.21it/s]\n",
            "Epoch 5/30 loss 16.52076: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:19<00:00, 30.98it/s]\n",
            "Epoch 5/30 val_loss 35.68436: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.40it/s]\n",
            "Epoch 6/30 loss 15.32579: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:19<00:00, 31.04it/s]\n",
            "Epoch 6/30 val_loss 35.65012: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.33it/s]\n",
            "Epoch 7/30 loss 14.37143: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:18<00:00, 31.31it/s]\n",
            "Epoch 7/30 val_loss 35.60575: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.42it/s]\n",
            "Epoch 8/30 loss 13.60504: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:18<00:00, 31.37it/s]\n",
            "Epoch 8/30 val_loss 35.67643: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.49it/s]\n",
            "Epoch 9/30 loss 12.96632: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:19<00:00, 31.12it/s]\n",
            "Epoch 9/30 val_loss 35.80515: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.69it/s]\n",
            "Epoch 10/30 loss 12.41750: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:18<00:00, 31.28it/s]\n",
            "Epoch 10/30 val_loss 35.98076: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.70it/s]\n",
            "Epoch 11/30 loss 11.94986: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:17<00:00, 31.73it/s]\n",
            "Epoch 11/30 val_loss 36.21244: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.32it/s]\n",
            "Epoch 12/30 loss 11.54670: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:18<00:00, 31.53it/s]\n",
            "Epoch 12/30 val_loss 36.29364: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 19.67it/s]\n",
            "Epoch 13/30 loss 11.18363: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:17<00:00, 31.60it/s]\n",
            "Epoch 13/30 val_loss 36.38980: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 19.65it/s]\n",
            "Epoch 14/30 loss 10.87610: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:17<00:00, 31.57it/s]\n",
            "Epoch 14/30 val_loss 36.67697: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.11it/s]\n",
            "Epoch 15/30 loss 10.59988: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:19<00:00, 30.79it/s]\n",
            "Epoch 15/30 val_loss 36.84120: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.09it/s]\n",
            "Epoch 16/30 loss 10.35116: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:20<00:00, 30.50it/s]\n",
            "Epoch 16/30 val_loss 37.07606: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 20.87it/s]\n",
            "Epoch 17/30 loss 10.12099: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:20<00:00, 30.50it/s]\n",
            "Epoch 17/30 val_loss 37.36862: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 20.81it/s]\n",
            "Epoch 18/30 loss 9.91760: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:19<00:00, 30.85it/s]\n",
            "Epoch 18/30 val_loss 37.44512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.21it/s]\n",
            "Epoch 19/30 loss 9.73375: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:19<00:00, 30.82it/s]\n",
            "Epoch 19/30 val_loss 37.80101: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.29it/s]\n",
            "Epoch 20/30 loss 9.56119: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:20<00:00, 30.58it/s]\n",
            "Epoch 20/30 val_loss 37.90215: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 20.97it/s]\n",
            "Epoch 21/30 loss 9.40825: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:20<00:00, 30.49it/s]\n",
            "Epoch 21/30 val_loss 38.14719: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.04it/s]\n",
            "Epoch 22/30 loss 9.26636: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:19<00:00, 30.91it/s]\n",
            "Epoch 22/30 val_loss 38.58336: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.10it/s]\n",
            "Epoch 23/30 loss 9.13371: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:20<00:00, 30.68it/s]\n",
            "Epoch 23/30 val_loss 38.53381: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 20.04it/s]\n",
            "Epoch 24/30 loss 9.00049: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:21<00:00, 30.14it/s]\n",
            "Epoch 24/30 val_loss 38.70800: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.17it/s]\n",
            "Epoch 25/30 loss 8.88983: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:19<00:00, 30.81it/s]\n",
            "Epoch 25/30 val_loss 38.98930: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.02it/s]\n",
            "Epoch 26/30 loss 8.77972: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:20<00:00, 30.74it/s]\n",
            "Epoch 26/30 val_loss 39.05095: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 20.95it/s]\n",
            "Epoch 27/30 loss 8.67287: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:20<00:00, 30.45it/s]\n",
            "Epoch 27/30 val_loss 39.19677: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 20.71it/s]\n",
            "Epoch 28/30 loss 8.58818: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:20<00:00, 30.40it/s]\n",
            "Epoch 28/30 val_loss 39.27253: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 20.91it/s]\n",
            "Epoch 29/30 loss 8.48526: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:19<00:00, 30.75it/s]\n",
            "Epoch 29/30 val_loss 39.57517: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:07<00:00, 21.15it/s]\n",
            "Epoch 30/30 loss 8.40686: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2459/2459 [01:20<00:00, 30.70it/s]\n",
            "Epoch 30/30 val_loss 39.86345: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [00:08<00:00, 18.88it/s]\n"
          ]
        }
      ],
      "source": [
        "[train_loss, val_loss] = fit(encoder, decoder, dataloader, epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loss)"
      ],
      "metadata": {
        "id": "XTzcMTcigbVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnur3Zsc-TdS"
      },
      "source": [
        "## Generando traducciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXlCFqEf-TdT"
      },
      "source": [
        "Una vez tenemos nuestro modelo entrenado, podemos utilizarlo para traducir frases del ingl√©s al castellano de la siguiente manera. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:31.925887Z",
          "start_time": "2020-09-04T13:12:31.915888Z"
        },
        "id": "T2wlMasw-TdT",
        "outputId": "65ec21c2-6d0d-45a9-e858-03d94daf0aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['he', 'ran', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'],\n",
              " ['er', 'rannte', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "input_sentence, output_sentence = dataset['train'][60]\n",
        "input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:32.615887Z",
          "start_time": "2020-09-04T13:12:32.598887Z"
        },
        "code_folding": [],
        "id": "Zvy6UPhh-TdT"
      },
      "outputs": [],
      "source": [
        "def predict(input_sentence):\n",
        "    # obtenemos el √∫ltimo estado oculto del encoder\n",
        "    encoder_outputs, hidden = encoder(input_sentence.unsqueeze(0))\n",
        "    # calculamos las salidas del decoder de manera recurrente\n",
        "    decoder_input = torch.tensor([[output_lang.word2index['SOS']]], device=device)\n",
        "    # iteramos hasta que el decoder nos de el token <eos>\n",
        "    outputs = []\n",
        "    decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
        "    i = 0\n",
        "    while True:\n",
        "        output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "        decoder_attentions[i] = attn_weights.data\n",
        "        i += 1\n",
        "        decoder_input = torch.argmax(output, axis=1).view(1, 1)\n",
        "        outputs.append(decoder_input.cpu().item())\n",
        "        if decoder_input.item() == output_lang.word2index['EOS']:\n",
        "            break\n",
        "    return output_lang.sentenceFromIndex(outputs), decoder_attentions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:32.789887Z",
          "start_time": "2020-09-04T13:12:32.775888Z"
        },
        "id": "ZvlfswaP-TdU",
        "outputId": "5bce7810-89ce-4770-be7e-5bb9c2fe04cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-bc211ece5c6b>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['er', 'rannte', '.', 'EOS']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "output_words, attn = predict(input_sentence)\n",
        "output_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npUOYjI8-TdU"
      },
      "source": [
        "## Visualizaci√≥n de atenci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRACWQvb-TdU"
      },
      "source": [
        "Una de las ventajas que nos da la capa de atenci√≥n es que nos permite visualizar en qu√© partes de los inputs se fija el modelo para generar cada una de las palabras en el output, dando un grado de explicabilidad a nuestro modelo (una propiedad siempre deseada en nuestro modelos de `Machine Learning`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:33.513889Z",
          "start_time": "2020-09-04T13:12:33.505889Z"
        },
        "id": "pHlvSd_3-TdU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    lim1, lim2 = input_sentence.index('EOS')+1, output_words.index('EOS')+1\n",
        "    fig = plt.figure(dpi=100)\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions[:lim2, :lim1].numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([' '] + input_sentence[:lim1], rotation=90)\n",
        "    ax.set_yticklabels([' '] + output_words)\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:34.273921Z",
          "start_time": "2020-09-04T13:12:34.160888Z"
        },
        "id": "hr782bl0-TdV",
        "outputId": "99f0de2d-124e-4b46-8f96-d94ee52d2c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "showAttention(input_lang.sentenceFromIndex(input_sentence.tolist()), output_words, attn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL-DXFaY-TdV"
      },
      "source": [
        "## Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLDSredh-TdV"
      },
      "source": [
        "En este post hemos visto como introducir mecanismos de atenci√≥n en nuestra arquitectura `encoder-decoder`, los cuales permiten a nuestra red neuronal focalizarse en partes concretas de los *inputs* a la hora de generar los *outputs*. Esta nueva capa no solo puede mejorar nuestros modelos sino que adem√°s tambi√©n es interpretable, d√°ndonos una idea del razonamiento detr√°s de las predicciones de nuestro modelo. Las redes neuronales con mejores prestaciones a d√≠a de hoy en tareas de `NLP`, los `transformers`, est√°n basados enteramente en este tipo de capas de atenci√≥n. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "233.594px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}