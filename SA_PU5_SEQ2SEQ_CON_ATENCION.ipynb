{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GioAcosta1/Traduccion-de-textos/blob/main/SA_PU5_SEQ2SEQ_CON_ATENCION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg90deR13qYE"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/041_attention/attention.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kzp2jHl3qY7"
      },
      "source": [
        "# **Práctica #5: Traducción automática de texto**\n",
        "\n",
        "*Centro Universitario de Ciencias Exactas e Ingenierías*\n",
        "\n",
        "*División de Tecnologías para la Integración Ciber-Humana*\n",
        "\n",
        "*Ingeniería Biomédica*\n",
        "\n",
        "\n",
        "*Mtra. Sofía Alejandra Aguilar Valdez*\n",
        "\n",
        "01 de diciembre de 2022"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Información del equipo\n",
        "\n",
        "**``NOMBRES:``**\n",
        "\n",
        "Acosta Martínez Edgar Giovanni\n",
        "\n",
        "\n",
        "**``CÓDIGOS:``** \n",
        "216590878\n",
        "\n",
        "**```LINK REPOSITORIO:```**\n"
      ],
      "metadata": {
        "id": "trDww3ZSX-Mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Contenido**\n",
        "1.   Resumen\n",
        "2.   Marco teórico\n",
        "3.   Objetivos\n",
        "4.   Materiales y métodos\n",
        "5.   Resultados\n",
        "6.   Discusión\n",
        "7.   Conclusiones\n",
        "8.   Referencias"
      ],
      "metadata": {
        "id": "qowdmVSlYKq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Resumen**\n"
      ],
      "metadata": {
        "id": "X9KlYezhYTp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Marco teórico**\n",
        "**2.1 ¿Qué es la Traducción automática neuronal(NMT)?**\n",
        "\n",
        "Traducir un texto es una tarea donde se realiza un modelo de probabilidad condicional **P(y|x)**, donde lo que se intenta es que para una frase *x* en un idioma particular, encontrar una frase *y* en otro idioma. De manera formal, el objetivo de esto es encontrar una frase de salida que maximice esta probabilidad condicional (la mejor frase). Utilizando la regla de Bayes, tal como lo exponen en [1], se obtiene la siguiente ecuación \n",
        "\n",
        "$$argmax_yP(y|x) -> argmax_yP(x|y)P(y)$$\n",
        "\n",
        "Donde P(x|y) indica como se traducen las palabras o frases (el modelo de traducción) y P(y) es el modelo de la lengua o idioma objetivo.\n",
        "Esto puede parecer una problema sencillo de modelar. No obstante, un idioma como tal es un sistema bastante complejo debido al diferente significado de una misma palabra en diferentes contextos. Esto complica las cosas. Un ejemplo, expuesto por [1] se visualiza en la siguiente imagen:\n",
        "\n",
        "![](https://miro.medium.com/max/503/1*L6kQV-5kdnz-HC_myrVjJw.png)\n",
        "\n",
        "En turco, *Yarın çalışacağım*, se traduce como *I will study tomorrow* en inglés o \"Yo estudiaré mañana\" en español. La cantidad de palabras es distinta, pero conlleva el mismo significado en todas las lenguas. Es así, que la tarea de traducir un texto conlleva la capacidad de razonar la relación semántica de las palabras, y sus distintos significados, dependiendo del contexto.\n",
        "\n",
        "Existen modelos de redes neuronales que intentan establecer estas relaciones entre palabras, y uno de ellos es el famoso modelo **Secuencia a Secuencia**, también conocido como **seq2seq**\n",
        "\n",
        "**2.2 Modelo Secuencia a Secuencia (seq2seq)**\n",
        "\n",
        "Las redes neuronales Secuencia a Secuencia (*seq2seq*) consisten en dos redes neuronales recurrentes (RNN) que, en conjunto, transforman una secuencia de entrada en otra de salida. Tal como lo expone [2], este tipo de esquema de redes cuenta con dos etapas: una etapa codificadora (*encoder*), donde una red condensa una secuencia en un vector, y una etapa decodificadora, donde el vector condensado se despliega en una nueva secuencia.\n",
        "\n",
        "Sutskever et al. [3] propuso esta arquitectura para procesamiento del lenguaje natural (NLP, por sus siglas en inglés). En esta arquitectura, se propone las dos RNN, una codificadora, y una decodificadora. En la siguiente imagen se observa esta arquitectura, donde se traduce la secuencia de entrada *A B C* a la secuencia de salida *W X Y Z* [3]. Nótese que en la secuencia existen unos indicadores llamados \"EOS\" que vienen de *End of Sentence*, que le indican a la red cuando comenzar a traducir y cuando parar.\n",
        "\n",
        "![](https://miro.medium.com/max/700/1*xPOMN3dZII02EFwIyQXpIA.png)\n",
        "\n",
        "**2.3 Mecanismo de atención**\n",
        "\n",
        "El modelo *seq2seq* funciona bien cuando se trata de secuencias cortas, ya que la entrada del decoder es el último estado oculto de la etapa del encoder. Con esto, mantener la relación del significado entre la frase origen y la frase objetivo se logra mantener mejor para las últimas palabras a comparación de las primeras. Esto nos indica que, a secuencias más grandes, nuestro modelo comienza a \"olvidar\" y deja de prestar atención a las primeras frases, pensando que no tienen mucha influencia en el significado global.\n",
        "\n",
        "Para solucionar esto, en 2017 sale a la luz un artículo que revolucionó la forma en que se trabaja en problemas de NLP, entre muchos más. *Attention Is All You Need* [4] nos plantea un **mecanismo de atención** capaz de mantener las relaciones entre las palabras de una frase, por medio de una ponderación matemática entre ellas. Y lo más interesante, es que estás mismas ponderaciones son calculadas por otra red neuronal.\n",
        "\n",
        "Es así, que esta capa de atención le da más o menor importancia a las palabras de una oración, dependiendo de cual palabra esta enfocando, por medio de una multiplicació matricial de sus ponderaciones calculadas previamente.\n",
        "\n",
        "Analizando el ejemplo de la traducción del idioma turco al inglés, el modelo ha logrado encontrar las primeras palabras *I Will Study* pero aún necesita encontrar la relación existente entre *Yarin* y la palabra que le hace falta. Para esto, utiliza el último estado oculto del decodificador, además de los estados ocultos de las dos secuencias de entrada, junto con su ponderación de atención y calcula el producto punto entre ellas. Esto nos dice, tomando las secuencias como vectores, que tan cercanos se encuentran (la relación entre ambos vectores).\n",
        "\n",
        "Lo que se obtiene es una puntuación, que debe ser normalizada como una distribución de probabilidad final para las palabras de entrada. En este caso, *Yarin* obtendría la puntuación más alta con respecto a *çalışacağım*. Por lo tanto, en lugar de utilizar el último estado oculto del decodificador, se utiliza la suma ponderada de los vectores de entrad para así predecir la siguiente palabra [1].\n",
        "\n",
        "En la siguiente imagen, se ilustra el ejemplo explicado anteriormente.\n",
        "\n",
        "![](https://miro.medium.com/max/700/1*1-dj7NIbfu7mi8eHzc5csA.png)"
      ],
      "metadata": {
        "id": "pr2VDN_RYWSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. Objetivos**\n",
        "\n",
        "**Objetivo general:**\n",
        "\n",
        "Realizar un modelo de Traducción Automática Neuronal (NMT) capaz de traducir oraciones del idioma alemán al idioma Inglés, y viceversa, utilizando un modelo Secuencia a Secuencia (*seq2seq*) con mecanismo de atención.\n",
        "\n",
        "**Objetivos específicos:**\n",
        "\n",
        "*   Obtener una base de datos que contenga frases en idioma alemán con su traducción al idioma inglés\n",
        "*   Realizar el preprocesamiento de la base de datos obtenida para eliminar caractéres no deseados que compliquen la traducción de las oraciones\n",
        "+   Realizar un modelo *seq2seq* con mecanismo de atención\n",
        "\n"
      ],
      "metadata": {
        "id": "09UKFXn0YcBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. Materiales y métodos**\n",
        "\n",
        "**4.1 Materiales**\n",
        "\n",
        "La base de datos utilizada para el entrenamiento del modelo neuronal presentado en este trabajo se obtuvo de [[5]](https://www.manythings.org/anki/). Consta de un archivo en formato .txt de frases en inglés con su traducción al alemán.\n",
        "\n",
        "Las frases se encuentran separadas por un tabulador (*\\t*) indicando su traducción y cada nueva traducción está separada por un salto de línea (*\\n*).\n",
        "\n",
        "En total, el archivo cuenta con 255817 pares de frases, de las cuales 196685 tienen una longitud menor de 10 palabras. El vocabulario en español cuenta con 13904 palabras y el vocabulario alemán cuenta con 28105 palabras.\n",
        "\n",
        "**4.2 Métodos**\n",
        "\n",
        "Para realizar la tarea de traducción de frases en alemán al idioma inglés, y viceversa, se utilizó el código desarrollado por [1], el cual traduce frases del idioma francés al idioma inglés.\n",
        "\n",
        "A continuación, se muestra el código de programación interactivo implementado en *Google Colab*, con cada una de sus secciones implicadas en la resolución del problema de traducción automática."
      ],
      "metadata": {
        "id": "BgX_KM2RYfWv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3O225-E-TdD"
      },
      "source": [
        "## Carga de datos y separación en pares de traducción (Pre-procesamiento de los datos)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se vincula drive para cargar la base de datos previamente descargada"
      ],
      "metadata": {
        "id": "EZksT6k06ans"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txXlqPPS-kTi",
        "outputId": "533f356e-293e-4f27-c259-77e4d9075320"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se definen funciones para leer el archivo y dividirlo en pares de frases de traducción"
      ],
      "metadata": {
        "id": "E3SqfQHe6goB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:52.733066Z",
          "start_time": "2020-09-04T12:31:52.725066Z"
        },
        "id": "Yb9LC0Jw-TdE"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "#Función para pasar de formato unicode a formato Ascii\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "#Función para convertir todas las frases en minusculas, sin espacio, y eliminando todos los caractéres extraños\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "#Lectura del archivo, separación en lineas y su divisón en pares de traducción normalizados\n",
        "def read_file(file, reverse=False):\n",
        "    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n",
        "    return pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se lee el archivo y se almacenan los pares de frases en una lista"
      ],
      "metadata": {
        "id": "ShD6Uw3D6oq4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.056055Z",
          "start_time": "2020-09-04T12:31:52.735065Z"
        },
        "id": "Te1Sc3Nr-TdG"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/drive/MyDrive/DEEP LEARNING/TRANSLATION PROYECT/deu.txt'\n",
        "pairs = read_file(filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se visualizan los pares de frases de manera aleatoria"
      ],
      "metadata": {
        "id": "s0LOyGJn6t4W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.071561Z",
          "start_time": "2020-09-04T12:31:56.058156Z"
        },
        "id": "Ds822BD0-TdH",
        "outputId": "be779abc-0d75-4e0b-990c-c2e0c55f02a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tom must choose between honor and death .',\n",
              " 'tom muss die ehre wahlen oder aber den tod .']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "random.choice(pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se necesita definir un *tokenizador*. La clase Lang se encarga de asignar un índice único a cada palabra, calculando también su frecuencia, para quedarnos con las palabras más frecuentes. Además, se definen dos tokens especiales: \"EOS\" y \"SOS\", que van a indicar el final, y el inicio de las oraciones, respectivamente. Aunado a esto, también se define el token \"PAD\" que va servir para ajustar todas las secuencias al tamaño máximo de longitud definido."
      ],
      "metadata": {
        "id": "Pi9XGDJ2608f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.087569Z",
          "start_time": "2020-09-04T12:31:56.074570Z"
        },
        "id": "qXe75QP5-TdI"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "PAD_token = 2\n",
        "\n",
        "class Lang:\n",
        "    #Se inicializa la clase\n",
        "    def __init__(self, name)\n",
        "        self.name = name\n",
        "        self.word2index = {\"SOS\": 0, \"EOS\": 1, \"PAD\": 2}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\"}\n",
        "        self.n_words = 3  # Count SOS, EOS and PAD\n",
        "\n",
        "    #Función para añadir oraciones\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "    #Función para tokenizar palabras\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "    #Función para pasar de oraciones a indices\n",
        "    def indexesFromSentence(self, sentence):\n",
        "        return [self.word2index[word] for word in sentence.split(' ')]\n",
        "    \n",
        "    #Función para pasar de índices a oraciones\n",
        "    def sentenceFromIndex(self, index):\n",
        "        return [self.index2word[ix] for ix in index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDKoy-zA-TdJ"
      },
      "source": [
        "Debido a las características de la capa de atención que se va a implementar, las frases deben tener una longitud homogénea (por las operaciones matriciales que se realizan). Es así como se define un tamaño máximo de 10. Además, también se definen ciertos prefijos del inglés junto con sus contracciones. Esto se utiliza para realizar filtrados en las oraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.103564Z",
          "start_time": "2020-09-04T12:31:56.088570Z"
        },
        "id": "LmnmiXwS-TdJ"
      },
      "outputs": [],
      "source": [
        "#Se define el tamaño máximo de longitud de las secuencias\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "#Se definen los prefijos y sus contracciones (filtro)\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "#Filtro para los prefijos\n",
        "def filterPairs(pairs, filters, lang=0):\n",
        "    return [p for p in pairs if p[lang].startswith(filters)]\n",
        "\n",
        "#Filtra por tamaño de longitud\n",
        "def trimPairs(pairs):\n",
        "    return [p for p in pairs if len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se integra la clase Lang y los filtros en una función que también permite cambiar el sentido de traducción. Además, se agrega el token \"EOS\" a las oraciones"
      ],
      "metadata": {
        "id": "ImZL5lssAOiO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.717657Z",
          "start_time": "2020-09-04T12:31:56.104565Z"
        },
        "code_folding": [
          0
        ],
        "id": "RTNhpWth-TdJ",
        "outputId": "000e8e8a-b63e-4f6e-ea5a-fafa6499bf24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tenemos 255817 pares de frases\n",
            "Tenemos 196685 pares de frases con longitud menor de 10\n",
            "Longitud vocabularios:\n",
            "spa 13904\n",
            "eng 28105\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i m unhappy . EOS', 'ich bin unglucklich . EOS']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def prepareData(file, filters=None, reverse=False):\n",
        "    #Se lee el archivo\n",
        "    pairs = read_file(file, reverse)\n",
        "    print(f\"Tenemos {len(pairs)} pares de frases\")\n",
        "    \n",
        "    #Si se desea, se filtra por prefijos\n",
        "    if filters is not None:\n",
        "        pairs = filterPairs(pairs, filters, int(reverse))\n",
        "        print(f\"Filtramos a {len(pairs)} pares de frases\")\n",
        "\n",
        "    #Se filtra por tamaño de longitud\n",
        "    pairs = trimPairs(pairs)\n",
        "    print(f\"Tenemos {len(pairs)} pares de frases con longitud menor de {MAX_LENGTH}\")\n",
        "\n",
        "    # Se decide la dirección de traducción\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang('eng')\n",
        "        output_lang = Lang('deu')\n",
        "    else:\n",
        "        input_lang = Lang('deu')\n",
        "        output_lang = Lang('eng')\n",
        "    \n",
        "    #Se añaden las oraciones para tokenizarlas\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "        \n",
        "        # Se añade el token \"EOS\"\n",
        "        pair[0] += \" EOS\"\n",
        "        pair[1] += \" EOS\"\n",
        "                           \n",
        "    print(\"Longitud vocabularios:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "                           \n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "#Se instancia la función con el dataset\n",
        "input_lang, output_lang, pairs = prepareData(filepath)\n",
        "\n",
        "#Si se desea filtrar por prefijos, se descomenta esta parte\n",
        "#input_lang, output_lang, pairs = prepareData('spa.txt', filters=eng_prefixes)\n",
        "                           \n",
        "random.choice(pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.730653Z",
          "start_time": "2020-09-04T12:31:59.719659Z"
        },
        "scrolled": true,
        "id": "ob2pRSmq-TdK",
        "outputId": "9a312934-6211-4be4-9aea-eb06f8804a94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[477, 90, 400]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#Se visualizan los índices dada una oración\n",
        "input_lang.indexesFromSentence('forgive us ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.754653Z",
          "start_time": "2020-09-04T12:31:59.731654Z"
        },
        "id": "-ti3rQ-B-TdK",
        "outputId": "6c69a525-cf9f-4ca5-bb44-02e830bcb477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['geh', 'deins', 'nuchtern', 'hallo']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#Se visualiza la oración dados unos índices\n",
        "output_lang.sentenceFromIndex([3, 1028, 647, 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBiO83gw-TdL"
      },
      "source": [
        "Tal como se mencionó con anterioridad, todas las oraciones deben tener la misma longitud para poder utilizar el mecanismo de atención. Por lo tanto, se añade un *padding* para rellenar aquellas oraciones menores que la máxima longitud establecida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:00.233655Z",
          "start_time": "2020-09-04T12:31:59.756655Z"
        },
        "code_folding": [],
        "id": "pKDqBMvQ-TdL",
        "outputId": "ad4d9203-8751-437d-84ef-e6618003b780",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(157348, 39337)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import torch\n",
        "#Se utiliza la gpu en caso de ser posible\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "#Clase que agrega el padding a las oraciones para tener secuencias homogéneas\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, input_lang, output_lang, pairs, max_length):\n",
        "        self.input_lang = input_lang\n",
        "        self.output_lang = output_lang\n",
        "        self.pairs = pairs\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    #Regrega la cantidad de secuencias\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "        \n",
        "    def __getitem__(self, ix):        \n",
        "        inputs = torch.tensor(self.input_lang.indexesFromSentence(self.pairs[ix][0]), device=device, dtype=torch.long)\n",
        "        outputs = torch.tensor(self.output_lang.indexesFromSentence(self.pairs[ix][1]), device=device, dtype=torch.long)\n",
        "        #Se agrega el padding\n",
        "        return torch.nn.functional.pad(inputs, (0, self.max_length - len(inputs)), 'constant', self.input_lang.word2index['PAD']), \\\n",
        "            torch.nn.functional.pad(outputs, (0, self.max_length - len(outputs)), 'constant', self.output_lang.word2index['PAD'])\n",
        "\n",
        "#Se realiza la separación de las secuencias en train (80%) y test (20%)\n",
        "train_size = len(pairs) * 80 // 100 \n",
        "train = pairs[:train_size]\n",
        "test = pairs[train_size:]\n",
        "\n",
        "#Se define el diccionario de dataset con las secuencias de train y test\n",
        "dataset = {\n",
        "    'train': Dataset(input_lang, output_lang, train, max_length=MAX_LENGTH),\n",
        "    'test': Dataset(input_lang, output_lang, test, max_length=MAX_LENGTH)\n",
        "}\n",
        "\n",
        "#Se visualiza el tamaño del dataset de entrenamiento y de test\n",
        "len(dataset['train']), len(dataset['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.359235Z",
          "start_time": "2020-09-04T12:32:00.234660Z"
        },
        "id": "eNwolvil-TdL",
        "outputId": "9e64b6d2-3fe0-4bf2-8f57-dbbcca330157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5, 4, 1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
              " tensor([5, 6, 1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Se visualiza cómo se encuentran los datos dentro del diccionario dataset\n",
        "input_sentence, output_sentence = dataset['train'][1]\n",
        "\n",
        "input_sentence, output_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.374232Z",
          "start_time": "2020-09-04T12:32:01.360239Z"
        },
        "id": "9U4jvnN3-TdM",
        "outputId": "c14e6755-1f54-4e08-cdfc-89dfb21cafce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['hi', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'],\n",
              " ['hallo', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#Se visualizan las oraciones a partir de los indices\n",
        "input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se define un *dataloader* para las secuencias de entrenamiento, con un tamaño de batch de 64, de manera aleatoria; y un *dataloader* de validación, con un tamaño de batch de 256."
      ],
      "metadata": {
        "id": "-c4pXCWFED3C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.405231Z",
          "start_time": "2020-09-04T12:32:01.375236Z"
        },
        "id": "z5eB75Dh-TdM",
        "outputId": "7bb0183a-927d-4159-dc82-2cbf2be3e668",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 10]), torch.Size([64, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\n",
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=64, shuffle=True),\n",
        "    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=256, shuffle=False),\n",
        "}\n",
        "\n",
        "#Se visualiza el tamaño del dataloader de entrenamiento con cada iteración\n",
        "inputs, outputs = next(iter(dataloader['train']))\n",
        "inputs.shape, outputs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T08:13:53.670033Z",
          "start_time": "2020-09-04T08:13:53.652976Z"
        },
        "id": "7fyrrO85-TdM"
      },
      "source": [
        "## Estructura del modelo seq2seq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder**"
      ],
      "metadata": {
        "id": "ujX_QrPOE0bP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0UYeHEG-TdN"
      },
      "source": [
        "Para la etapa de *encoder*, se utiliza una red neuronal recurrente (RNN). Se tiene una primera capa de tipo *embedding* que obtendrá la representación vectorial de las secuencias de entrada. Estos vectores resultantes, serán la entrada de la RNN. Está puede ser una LSTM o una GRU (Gated-Recurrent Units).\n",
        "En este caso particular, se utilizara una GRU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.421231Z",
          "start_time": "2020-09-04T12:32:01.406231Z"
        },
        "id": "PepdDJ_S-TdN"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
        "        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, input_sentences):\n",
        "        embedded = self.embedding(input_sentences)\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.452231Z",
          "start_time": "2020-09-04T12:32:01.422235Z"
        },
        "id": "nqc_34ET-TdN",
        "outputId": "ccad04b0-db2b-4bee-f8b2-a0aff4202c17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#Se visualiza la forma que tendrá la salida del encoder\n",
        "encoder = Encoder(input_size=input_lang.n_words)\n",
        "encoder_outputs, encoder_hidden = encoder(torch.randint(0, input_lang.n_words, (64, 10)))\n",
        "\n",
        "# [tamaño de batch, tamaño de secuencia, tamaño del estado oculto]\n",
        "encoder_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.468231Z",
          "start_time": "2020-09-04T12:32:01.453237Z"
        },
        "id": "oO2I-3pO-TdO",
        "outputId": "5b5edd34-9c14-4dac-a498-65d7c1a567ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#Se visualiza la forma que tendrá el estado oculto de cada palabra\n",
        "# [número de capas, tamaño de batch, Tamaño del estado oculto]\n",
        "encoder_hidden.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdGp8SJs-TdO"
      },
      "source": [
        "**Decoder con mecanismo de atención**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9zafPl6-TdO"
      },
      "source": [
        "Para la etapa de *decoder*, se utilizarán las entradas y estado oculto del *decoder* para encontrar pesos que ponderen las salidas del *encoder*, los cuales se combinan con las entradas del *decoder, para así obtener las representaciones vectoriales de entrada para la capa recurrente de esta etapa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:43:51.447608Z",
          "start_time": "2020-09-04T13:43:51.433585Z"
        },
        "id": "EHLuOlsj-TdP"
      },
      "outputs": [],
      "source": [
        "class AttnDecoder(torch.nn.Module):\n",
        "    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2, max_length=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
        "        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
        "        self.out = torch.nn.Linear(hidden_size, input_size)\n",
        "        \n",
        "        # Capa de mecanismo de atención\n",
        "        self.attn = torch.nn.Linear(hidden_size + embedding_size, max_length)\n",
        "        self.attn_combine = torch.nn.Linear(hidden_size * 2, hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, input_words, hidden, encoder_outputs):\n",
        "        #Se obtienen los vectores embedding\n",
        "        embedded = self.embedding(input_words)\n",
        "        #Se obtiene el vector de ponderación de la capa de atención\n",
        "        attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1))) \n",
        "        #Se ajustan las salidas del encoder con este vector de ponderación\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
        "        output = torch.cat((embedded.squeeze(1), attn_applied.squeeze(1)), 1)\n",
        "        #Se aplica la capa de atención\n",
        "        output = self.attn_combine(output)\n",
        "        output = torch.nn.functional.relu(output)\n",
        "        #Se aplica la capa recurrente, con las salidas ajustas del encoder y el estado oculto\n",
        "        output, hidden = self.gru(output.unsqueeze(1), hidden)\n",
        "        #Se obtiene la secuencia de salida\n",
        "        output = self.out(output.squeeze(1))        \n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.539231Z",
          "start_time": "2020-09-04T12:32:01.484236Z"
        },
        "id": "PT4kLJ7M-TdP",
        "outputId": "5d14af6d-0bee-439c-e5ce-747810a512d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-bc211ece5c6b>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 28105])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#Se visualiza la forma del vector de salida del decoder\n",
        "decoder = AttnDecoder(input_size=output_lang.n_words)\n",
        "decoder_output, decoder_hidden, attn_weights = decoder(torch.randint(0, output_lang.n_words, (64, 1)), encoder_hidden, encoder_outputs)\n",
        "\n",
        "# [Tamaño de batch, Tamaño de vocabulario]\n",
        "decoder_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.547232Z",
          "start_time": "2020-09-04T12:32:01.541233Z"
        },
        "id": "A55cOQRH-TdQ",
        "outputId": "7236fb94-acca-453e-bd7b-20b6ff4ea6e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#Se visualiza el tamaño del estado oculto del decoder\n",
        "# [Número de capas, Tamaño de batch, Tamaño del estado oculto]\n",
        "decoder_hidden.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.578233Z",
          "start_time": "2020-09-04T12:32:01.573232Z"
        },
        "id": "ep23mzzU-TdQ",
        "outputId": "06fd974f-f856-4bc3-bdab-c5160088752c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "#Se visualiza el tamaño del vector de ponderación para el mecanismo de atención\n",
        "# [Tamaño de batch, Longitud]\n",
        "attn_weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or4e2C0m-TdQ"
      },
      "source": [
        "## Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAjH0Drz-TdR"
      },
      "source": [
        "Para el entrenamiento del modelo, debido a que se tienen dos redes neuronales recurrentes (*encoder* y *decoder*), se requieren dos optimizadores. El encoder recibe la frase en el idioma original y se obtiene el estado oculto. Este estado oculto será la entrada del *decoder*, que identificará el token *SOS*, para así generar la primera palabra de la frase. Así, en la siguiente iteración, se utilizara como entrada la anterior salida del decoder, para llegar al token *EOS* y terminar la traducción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.593231Z",
          "start_time": "2020-09-04T12:32:01.579232Z"
        },
        "code_folding": [
          3
        ],
        "id": "9_o25Nh4-TdR"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "#La función fit recibe la red encoder, la red decoder, el dataloader y la cantidad de épocas\n",
        "def fit(encoder, decoder, dataloader, epochs=10):\n",
        "    encoder.to(device)\n",
        "    decoder.to(device)\n",
        "    #Se definen ambos optimizadores con Adam y su respectivo learning rate de 0.001\n",
        "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
        "    #Se define la función de perdida\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        train_loss = []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            #Se adquieren las oraciones de entrada y la traducción\n",
        "            input_sentences, output_sentences = batch\n",
        "            bs = input_sentences.shape[0]                    \n",
        "            loss = 0\n",
        "            #Se ajustan los gradientes a cero\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "            # Se obtieen el último estado oculto del encoder y sus salidas\n",
        "            encoder_outputs, hidden = encoder(input_sentences)\n",
        "            #Se inicializa el decoder con el token \"SOS\" y se itera para obtener sus salidas\n",
        "            #La entrada del decoder pasa a ser su salida y estado oculto anterior\n",
        "            decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
        "            for i in range(output_sentences.shape[1]):\n",
        "                output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "                #Se va almacenando la función de perdida\n",
        "                loss += criterion(output, output_sentences[:, i].view(bs))     \n",
        "                #La salida del decoder sirve como su entrada para la siguiente predicción\n",
        "                decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
        "            #Optimización del modelo\n",
        "            loss.backward()\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            #Se imprime la función de perdida durante cada época\n",
        "            bar.set_description(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f}\")\n",
        "\n",
        "        #Validación del modelo    \n",
        "        val_loss = []\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        with torch.no_grad():\n",
        "            bar = tqdm(dataloader['test'])\n",
        "            for batch in bar:\n",
        "                input_sentences, output_sentences = batch\n",
        "                bs = input_sentences.shape[0]  \n",
        "                loss = 0\n",
        "                # obtenemos el último estado oculto del encoder\n",
        "                encoder_outputs, hidden = encoder(input_sentences)\n",
        "                # calculamos las salidas del decoder de manera recurrente\n",
        "                decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
        "                for i in range(output_sentences.shape[1]):\n",
        "                    output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "                    loss += criterion(output, output_sentences[:, i].view(bs))     \n",
        "                    # el siguiente input será la palabra predicha\n",
        "                    decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
        "                val_loss.append(loss.item())\n",
        "                #Se imprime la validación de la función de perdida durante cada época de entrenamiento\n",
        "                bar.set_description(f\"Epoch {epoch}/{epochs} val_loss {np.mean(val_loss):.5f}\")\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predicciones del modelo"
      ],
      "metadata": {
        "id": "k2sRvh4lN6yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para poder visualizar las traducciones del modelo entrenado, se define una función *predict* que realiza un proceso iterativo parecido al entrenamiento con el *decoder*.\n",
        "\n",
        "Se inicia el decoder con el token \"SOS\" y el último estado oculto del encoder. A partir de esto, comienza a realizar predicciones, y cada una de estas secuencias de salida, se convierten en su entrada junto con el estado oculto resultante, hasta que predice el token \"EOS\" y se termina la traducción."
      ],
      "metadata": {
        "id": "dhkOvBhVOMrJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:32.615887Z",
          "start_time": "2020-09-04T13:12:32.598887Z"
        },
        "code_folding": [],
        "id": "Zvy6UPhh-TdT"
      },
      "outputs": [],
      "source": [
        "def predict(input_sentence):\n",
        "    # obtenemos el último estado oculto del encoder\n",
        "    encoder_outputs, hidden = encoder(input_sentence.unsqueeze(0))\n",
        "    # calculamos las salidas del decoder de manera recurrente\n",
        "    decoder_input = torch.tensor([[output_lang.word2index['SOS']]], device=device)\n",
        "    # iteramos hasta que el decoder nos de el token <eos>\n",
        "    outputs = []\n",
        "    decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
        "    i = 0\n",
        "    while True:\n",
        "        output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "        decoder_attentions[i] = attn_weights.data\n",
        "        i += 1\n",
        "        decoder_input = torch.argmax(output, axis=1).view(1, 1)\n",
        "        outputs.append(decoder_input.cpu().item())\n",
        "        if decoder_input.item() == output_lang.word2index['EOS']:\n",
        "            break\n",
        "    return output_lang.sentenceFromIndex(outputs), decoder_attentions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. Resultados**"
      ],
      "metadata": {
        "id": "AdE02lxwYkL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al entrenar el modelo durante 30 épocas, se obtiene el siguiente proceso de entrenamiento:"
      ],
      "metadata": {
        "id": "JQni0oW-Pxvn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:58:02.367102Z",
          "start_time": "2020-09-04T12:32:01.595236Z"
        },
        "id": "QF04SFW7-TdR",
        "outputId": "8d4d62ea-25fb-49d3-86ca-94ce37b90cc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2459 [00:00<?, ?it/s]<ipython-input-29-bc211ece5c6b>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n",
            "Epoch 1/30 loss 31.28985: 100%|██████████| 2459/2459 [01:22<00:00, 29.94it/s]\n",
            "Epoch 1/30 val_loss 41.73479: 100%|██████████| 154/154 [00:07<00:00, 20.37it/s]\n",
            "Epoch 2/30 loss 23.42449: 100%|██████████| 2459/2459 [01:19<00:00, 30.98it/s]\n",
            "Epoch 2/30 val_loss 38.71156: 100%|██████████| 154/154 [00:07<00:00, 21.28it/s]\n",
            "Epoch 3/30 loss 20.23360: 100%|██████████| 2459/2459 [01:18<00:00, 31.20it/s]\n",
            "Epoch 3/30 val_loss 37.29097: 100%|██████████| 154/154 [00:07<00:00, 21.68it/s]\n",
            "Epoch 4/30 loss 18.08396: 100%|██████████| 2459/2459 [01:18<00:00, 31.41it/s]\n",
            "Epoch 4/30 val_loss 36.13682: 100%|██████████| 154/154 [00:07<00:00, 21.21it/s]\n",
            "Epoch 5/30 loss 16.52076: 100%|██████████| 2459/2459 [01:19<00:00, 30.98it/s]\n",
            "Epoch 5/30 val_loss 35.68436: 100%|██████████| 154/154 [00:07<00:00, 21.40it/s]\n",
            "Epoch 6/30 loss 15.32579: 100%|██████████| 2459/2459 [01:19<00:00, 31.04it/s]\n",
            "Epoch 6/30 val_loss 35.65012: 100%|██████████| 154/154 [00:07<00:00, 21.33it/s]\n",
            "Epoch 7/30 loss 14.37143: 100%|██████████| 2459/2459 [01:18<00:00, 31.31it/s]\n",
            "Epoch 7/30 val_loss 35.60575: 100%|██████████| 154/154 [00:07<00:00, 21.42it/s]\n",
            "Epoch 8/30 loss 13.60504: 100%|██████████| 2459/2459 [01:18<00:00, 31.37it/s]\n",
            "Epoch 8/30 val_loss 35.67643: 100%|██████████| 154/154 [00:07<00:00, 21.49it/s]\n",
            "Epoch 9/30 loss 12.96632: 100%|██████████| 2459/2459 [01:19<00:00, 31.12it/s]\n",
            "Epoch 9/30 val_loss 35.80515: 100%|██████████| 154/154 [00:07<00:00, 21.69it/s]\n",
            "Epoch 10/30 loss 12.41750: 100%|██████████| 2459/2459 [01:18<00:00, 31.28it/s]\n",
            "Epoch 10/30 val_loss 35.98076: 100%|██████████| 154/154 [00:07<00:00, 21.70it/s]\n",
            "Epoch 11/30 loss 11.94986: 100%|██████████| 2459/2459 [01:17<00:00, 31.73it/s]\n",
            "Epoch 11/30 val_loss 36.21244: 100%|██████████| 154/154 [00:07<00:00, 21.32it/s]\n",
            "Epoch 12/30 loss 11.54670: 100%|██████████| 2459/2459 [01:18<00:00, 31.53it/s]\n",
            "Epoch 12/30 val_loss 36.29364: 100%|██████████| 154/154 [00:07<00:00, 19.67it/s]\n",
            "Epoch 13/30 loss 11.18363: 100%|██████████| 2459/2459 [01:17<00:00, 31.60it/s]\n",
            "Epoch 13/30 val_loss 36.38980: 100%|██████████| 154/154 [00:07<00:00, 19.65it/s]\n",
            "Epoch 14/30 loss 10.87610: 100%|██████████| 2459/2459 [01:17<00:00, 31.57it/s]\n",
            "Epoch 14/30 val_loss 36.67697: 100%|██████████| 154/154 [00:07<00:00, 21.11it/s]\n",
            "Epoch 15/30 loss 10.59988: 100%|██████████| 2459/2459 [01:19<00:00, 30.79it/s]\n",
            "Epoch 15/30 val_loss 36.84120: 100%|██████████| 154/154 [00:07<00:00, 21.09it/s]\n",
            "Epoch 16/30 loss 10.35116: 100%|██████████| 2459/2459 [01:20<00:00, 30.50it/s]\n",
            "Epoch 16/30 val_loss 37.07606: 100%|██████████| 154/154 [00:07<00:00, 20.87it/s]\n",
            "Epoch 17/30 loss 10.12099: 100%|██████████| 2459/2459 [01:20<00:00, 30.50it/s]\n",
            "Epoch 17/30 val_loss 37.36862: 100%|██████████| 154/154 [00:07<00:00, 20.81it/s]\n",
            "Epoch 18/30 loss 9.91760: 100%|██████████| 2459/2459 [01:19<00:00, 30.85it/s]\n",
            "Epoch 18/30 val_loss 37.44512: 100%|██████████| 154/154 [00:07<00:00, 21.21it/s]\n",
            "Epoch 19/30 loss 9.73375: 100%|██████████| 2459/2459 [01:19<00:00, 30.82it/s]\n",
            "Epoch 19/30 val_loss 37.80101: 100%|██████████| 154/154 [00:07<00:00, 21.29it/s]\n",
            "Epoch 20/30 loss 9.56119: 100%|██████████| 2459/2459 [01:20<00:00, 30.58it/s]\n",
            "Epoch 20/30 val_loss 37.90215: 100%|██████████| 154/154 [00:07<00:00, 20.97it/s]\n",
            "Epoch 21/30 loss 9.40825: 100%|██████████| 2459/2459 [01:20<00:00, 30.49it/s]\n",
            "Epoch 21/30 val_loss 38.14719: 100%|██████████| 154/154 [00:07<00:00, 21.04it/s]\n",
            "Epoch 22/30 loss 9.26636: 100%|██████████| 2459/2459 [01:19<00:00, 30.91it/s]\n",
            "Epoch 22/30 val_loss 38.58336: 100%|██████████| 154/154 [00:07<00:00, 21.10it/s]\n",
            "Epoch 23/30 loss 9.13371: 100%|██████████| 2459/2459 [01:20<00:00, 30.68it/s]\n",
            "Epoch 23/30 val_loss 38.53381: 100%|██████████| 154/154 [00:07<00:00, 20.04it/s]\n",
            "Epoch 24/30 loss 9.00049: 100%|██████████| 2459/2459 [01:21<00:00, 30.14it/s]\n",
            "Epoch 24/30 val_loss 38.70800: 100%|██████████| 154/154 [00:07<00:00, 21.17it/s]\n",
            "Epoch 25/30 loss 8.88983: 100%|██████████| 2459/2459 [01:19<00:00, 30.81it/s]\n",
            "Epoch 25/30 val_loss 38.98930: 100%|██████████| 154/154 [00:07<00:00, 21.02it/s]\n",
            "Epoch 26/30 loss 8.77972: 100%|██████████| 2459/2459 [01:20<00:00, 30.74it/s]\n",
            "Epoch 26/30 val_loss 39.05095: 100%|██████████| 154/154 [00:07<00:00, 20.95it/s]\n",
            "Epoch 27/30 loss 8.67287: 100%|██████████| 2459/2459 [01:20<00:00, 30.45it/s]\n",
            "Epoch 27/30 val_loss 39.19677: 100%|██████████| 154/154 [00:07<00:00, 20.71it/s]\n",
            "Epoch 28/30 loss 8.58818: 100%|██████████| 2459/2459 [01:20<00:00, 30.40it/s]\n",
            "Epoch 28/30 val_loss 39.27253: 100%|██████████| 154/154 [00:07<00:00, 20.91it/s]\n",
            "Epoch 29/30 loss 8.48526: 100%|██████████| 2459/2459 [01:19<00:00, 30.75it/s]\n",
            "Epoch 29/30 val_loss 39.57517: 100%|██████████| 154/154 [00:07<00:00, 21.15it/s]\n",
            "Epoch 30/30 loss 8.40686: 100%|██████████| 2459/2459 [01:20<00:00, 30.70it/s]\n",
            "Epoch 30/30 val_loss 39.86345: 100%|██████████| 154/154 [00:08<00:00, 18.88it/s]\n"
          ]
        }
      ],
      "source": [
        "[train_loss, val_loss] = fit(encoder, decoder, dataloader, epochs=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al **inicio del entrenamiento**, la función de perdida es de 31.28985 y su validación es de 41.73479. Al **finalizar el entrenamiento**, la función de perdida es de 8.40686 y su validación es de 39.86345."
      ],
      "metadata": {
        "id": "NwD-y5d1P4CF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnur3Zsc-TdS"
      },
      "source": [
        "## Visualización de traducción"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para poder ver en funcionamiento el modelo, se obtiene una oración del dataset junto con su predicción. Esta última sirve para evaluar la calidad de predicción del modelo. Así, la oración obtenida se introduce en la función de predicción y obtenemos la secuencia de salida."
      ],
      "metadata": {
        "id": "igNn1kRQSnIK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:31.925887Z",
          "start_time": "2020-09-04T13:12:31.915888Z"
        },
        "id": "T2wlMasw-TdT",
        "outputId": "65ec21c2-6d0d-45a9-e858-03d94daf0aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['he', 'ran', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'],\n",
              " ['er', 'rannte', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "#Obtenemos una secuencia del dataset y su traducción, para saber cuál es el resultado más acertado\n",
        "input_sentence, output_sentence = dataset['train'][60]\n",
        "input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:32.789887Z",
          "start_time": "2020-09-04T13:12:32.775888Z"
        },
        "id": "ZvlfswaP-TdU",
        "outputId": "5bce7810-89ce-4770-be7e-5bb9c2fe04cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-bc211ece5c6b>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['er', 'rannte', '.', 'EOS']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "#Se realiza la predicción y se muestra la oración obtenida.\n",
        "output_words, attn = predict(input_sentence)\n",
        "output_words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso particular, donde la secuencia de entrada es *he ran. EOS*, y traducción es *er rannte. EOS*, el modelo entrenado obtuvo la secuencia *er rannte. EOS*."
      ],
      "metadata": {
        "id": "RhKTzwW5S_ly"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npUOYjI8-TdU"
      },
      "source": [
        "## Visualización de atención"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRACWQvb-TdU"
      },
      "source": [
        "Una vez generada la secuencia, podemos analizar los mecanismos de atención implicados en la obtención de esta misma a partir de una matriz de visualización de atención, donde cada palabra guarda una relación con otra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:33.513889Z",
          "start_time": "2020-09-04T13:12:33.505889Z"
        },
        "id": "pHlvSd_3-TdU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    lim1, lim2 = input_sentence.index('EOS')+1, output_words.index('EOS')+1\n",
        "    fig = plt.figure(dpi=100)\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions[:lim2, :lim1].numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([' '] + input_sentence[:lim1], rotation=90)\n",
        "    ax.set_yticklabels([' '] + output_words)\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:34.273921Z",
          "start_time": "2020-09-04T13:12:34.160888Z"
        },
        "id": "hr782bl0-TdV",
        "outputId": "99f0de2d-124e-4b46-8f96-d94ee52d2c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "showAttention(input_lang.sentenceFromIndex(input_sentence.tolist()), output_words, attn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**6. Discusión**\n",
        "\n",
        "El entrenamiento del modelo *seq2seq* con un mecanismo de atención integrado, sufrió de overfitting. Esto se visualiza gracias a que la función de perdida en la validación comenzó a aumentar conforme aumentaban las épocas.\n",
        "Por lo tanto, el modelo generado logra traducir bien solo aquellas oraciones con las que realizó el entrenamiento. Es así, que, si se introduce una nueva oración, el modelo tendrá bastantes problemas para generar una traducción óptima.\n",
        "\n",
        "El overfitting también se puede visualizar en la matriz de visualización de atención, donde se nota que la palabra *ran*, *rannte* y *er* tiene una relación mayor con el token especial *EOS*. Esto indica que en el modelo solo basta tener la palabra e identificar ese token, para ya saber la traducción.\n",
        "\n",
        "En posteriores trabajos, se debe realizar un entrenamiento con mayor cantidad de secuencias, variando el tamaño máximo de la longitud y variando los hiperparámetros del modelo. Además, sería necesario generar una comparación detallada del entrenamiento de un modelo *seq2seq*, un modelo *seq2seq* con mecanismo de atención, y un modelo *Transformer*. Con esto, se definiría las ventajas y desventajas de cada modelo con respecto al tamaño de las secuencias y su capacidad de traducción.\n"
      ],
      "metadata": {
        "id": "XvCouxJsYn_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**7. Conclusiones**\n",
        "\n",
        "Realizar modelos *seq2seq* permite generar una abstracción clara del proceso de traducción de las secuencias de entrada, ya que la división del modelo en dos etapas, es una herramienta útil para comprender cada parte y su conexión global con la secuencia de salida.\n",
        "\n",
        "Este tipo de modelos puede funcionar bien para tareas de traducción de textos, resumir algún párrafo, corregir errores gramaticales. No obstante, debido los datos de entrenamiento, el modelo sufrió de overfitting, por lo cual nuevas frases de entrada tendrán traducciones pobres de salida. \n",
        "\n",
        "En futuros trabajos, se debe optar por variar el tamaño de la secuencia, y realizar modificaciones a los hiperparámetros del modelo."
      ],
      "metadata": {
        "id": "OnUg-yMYYtkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**8. Referencias**\n",
        "\n",
        "[1] Yasar, A. (2021). Neuronal Machine Translation: Inner Workings, Seq2Seq, and Transformers.\n",
        "\n",
        "[2] Robertson, S. (s.f.). NLP from skratch: Translation with a sequence to sequence network and attention. https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "\n",
        "[3] Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. Advances in neural information processing systems, 27.\n",
        "\n",
        "[4] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30."
      ],
      "metadata": {
        "id": "x2M0PKb0YyV2"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "233.594px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}